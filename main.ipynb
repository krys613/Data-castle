{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>word_seg</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102272</th>\n",
       "      <td>102272</td>\n",
       "      <td>556634 837240 427848 753262 481583 140141 8560...</td>\n",
       "      <td>3849 789842 518787 1033823 1129275 906378 1381...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102273</th>\n",
       "      <td>102273</td>\n",
       "      <td>611112 599682 626902 569999 178976 452751 1044...</td>\n",
       "      <td>340401 966562 520355 599826 811205 520477 5592...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102274</th>\n",
       "      <td>102274</td>\n",
       "      <td>865510 7368 891719 697742 641202 641202 122001...</td>\n",
       "      <td>139132 816903 1070929 506513 1033823 843921 92...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102275</th>\n",
       "      <td>102275</td>\n",
       "      <td>828236 1269463 474675 180178 1209583 906756 50...</td>\n",
       "      <td>287730 1275770 583072 739365 548903 655201 983...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102276</th>\n",
       "      <td>102276</td>\n",
       "      <td>538313 420000 942897 836887 7368 359838 42610 ...</td>\n",
       "      <td>544010 964016 816903 460600 545370 94560 74756...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                            article  \\\n",
       "102272  102272  556634 837240 427848 753262 481583 140141 8560...   \n",
       "102273  102273  611112 599682 626902 569999 178976 452751 1044...   \n",
       "102274  102274  865510 7368 891719 697742 641202 641202 122001...   \n",
       "102275  102275  828236 1269463 474675 180178 1209583 906756 50...   \n",
       "102276  102276  538313 420000 942897 836887 7368 359838 42610 ...   \n",
       "\n",
       "                                                 word_seg  class  \n",
       "102272  3849 789842 518787 1033823 1129275 906378 1381...     14  \n",
       "102273  340401 966562 520355 599826 811205 520477 5592...      8  \n",
       "102274  139132 816903 1070929 506513 1033823 843921 92...     12  \n",
       "102275  287730 1275770 583072 739365 548903 655201 983...      4  \n",
       "102276  544010 964016 816903 460600 545370 94560 74756...     11  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>word_seg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102272</th>\n",
       "      <td>102272</td>\n",
       "      <td>7368 7368 195449 239755 487625 603710 468653 1...</td>\n",
       "      <td>816903 816903 703339 920327 1081147 529032 816...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102273</th>\n",
       "      <td>102273</td>\n",
       "      <td>1252069 569999 1044285 881890 581131 1030656 6...</td>\n",
       "      <td>1000015 520477 386754 1025743 309073 672904 55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102274</th>\n",
       "      <td>102274</td>\n",
       "      <td>15318 760667 611112 599682 626902 569999 51230...</td>\n",
       "      <td>132454 340401 966562 520355 599826 937273 3304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102275</th>\n",
       "      <td>102275</td>\n",
       "      <td>40494 1080029 7368 10985 473865 119827 773255 ...</td>\n",
       "      <td>135124 816903 1064720 41306 1163183 63438 1104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102276</th>\n",
       "      <td>102276</td>\n",
       "      <td>266913 732391 195449 21350 468653 1222182 1772...</td>\n",
       "      <td>490535 866576 595714 374964 526298 954801 1080...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                            article  \\\n",
       "102272  102272  7368 7368 195449 239755 487625 603710 468653 1...   \n",
       "102273  102273  1252069 569999 1044285 881890 581131 1030656 6...   \n",
       "102274  102274  15318 760667 611112 599682 626902 569999 51230...   \n",
       "102275  102275  40494 1080029 7368 10985 473865 119827 773255 ...   \n",
       "102276  102276  266913 732391 195449 21350 468653 1222182 1772...   \n",
       "\n",
       "                                                 word_seg  \n",
       "102272  816903 816903 703339 920327 1081147 529032 816...  \n",
       "102273  1000015 520477 386754 1025743 309073 672904 55...  \n",
       "102274  132454 340401 966562 520355 599826 937273 3304...  \n",
       "102275  135124 816903 1064720 41306 1163183 63438 1104...  \n",
       "102276  490535 866576 595714 374964 526298 954801 1080...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102277 entries, 0 to 102276\n",
      "Data columns (total 4 columns):\n",
      "id          102277 non-null int64\n",
      "article     102277 non-null object\n",
      "word_seg    102277 non-null object\n",
      "class       102277 non-null int64\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102277 entries, 0 to 102276\n",
      "Data columns (total 3 columns):\n",
      "id          102277 non-null int64\n",
      "article     102277 non-null object\n",
      "word_seg    102277 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the train data into train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "columns = df_train.columns\n",
    "columns = columns.drop('class')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[columns], df_train[['class']], \n",
    "                                                    test_size=0.3, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71593, 3)\n",
      "(30684, 3)\n",
      "(71593, 1)\n",
      "(30684, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the original digital data to tfidf features and save for traditional single model machine learning\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns='article', inplace=True)\n",
    "df_test.drop(columns='article', inplace=True)\n",
    "\n",
    "f_all = pd.concat(objs=[df_train, df_test], axis=0, sort=True)\n",
    "y_train = (df_train['class'] - 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=3, max_df=0.9, sublinear_tf=True)\n",
    "vectorizer.fit(df_train['word_seg'])\n",
    "x_train = vectorizer.transform(df_train['word_seg'])\n",
    "x_test = vectorizer.transform(df_test['word_seg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (x_train, y_train, x_test)\n",
    "fp = open('data_w_tfidf.pkl', 'wb')\n",
    "pickle.dump(data, fp)\n",
    "fp.close()\n",
    "\n",
    "t_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.6977252364\n"
     ]
    }
   ],
   "source": [
    "#mark the time for processing\n",
    "print(format((t_end-t_start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the \"word_seg\" context, training word vec, generate and save word_idx_dict and vectors_arr for deep learning\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import csv,sys\n",
    "vector_size = 100\n",
    "\n",
    "maxInt = sys.maxsize\n",
    "decrement = True\n",
    "while decrement:\n",
    "    # decrease the maxInt value by factor 10\n",
    "    # as long as the OverflowError occurs.\n",
    "    decrement = False\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "        decrement = True\n",
    "\n",
    "def sentence2list(sentence):\n",
    "    return sentence.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train = list(df_train.loc[:, 'word_seg'].apply(sentence2list))\n",
    "sentences_test = list(df_test.loc[:, 'word_seg'].apply(sentence2list))\n",
    "sentences = sentences_train + sentences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences=sentences, size=vector_size, window=5, min_count=5, workers=8, sg=0, iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = model.wv\n",
    "vocab_list = wv.index2word\n",
    "word_idx_dict = {}\n",
    "for idx, word in enumerate(vocab_list):\n",
    "    word_idx_dict[word] = idx\n",
    "    \n",
    "vectors_arr = wv.vectors\n",
    "vectors_arr = np.concatenate((np.zeros(vector_size)[np.newaxis, :], vectors_arr), axis=0)#第0位置的vector为'unk'的vector\n",
    "\n",
    "f_wordidx = open('word_seg_word_idx_dict.pkl', 'wb')\n",
    "f_vectors = open('word_seg_vectors_arr.pkl', 'wb')\n",
    "pickle.dump(word_idx_dict, f_wordidx)\n",
    "pickle.dump(vectors_arr, f_vectors)\n",
    "f_wordidx.close()\n",
    "f_vectors.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "y_pred = svc.predict(y_test)\n",
    "acc_svc = round(svc.score(x_train, y_train) * 100, 2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "Y_pred = logreg.predict(x_test)\n",
    "acc_log = round(logreg.score(x_train, y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "acc_knn = round(knn.score(x_train, y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(x_train, y_train)\n",
    "y_pred = gaussian.predict(x_test)\n",
    "acc_gaussian = round(gaussian.score(x_train, y_train) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "acc_decision_tree = round(decision_tree.score(x_train, y_train) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_pred = random_forest.predict(x_test)\n",
    "random_forest.score(x_train, y_train)\n",
    "acc_random_forest = round(random_forest.score(x_train, y_train) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"id\": df_test[\"id\"],\n",
    "        \"class\": y_pred\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to use f1 score\n",
    "import pickle\n",
    "\n",
    "def f1_score_vali(preds, data_vali):\n",
    "    labels = data_vali.get_label()\n",
    "    preds = np.argmax(preds.reshape(19, -1), axis = 0)\n",
    "    score_vali = f1_score(y_true = labels, y_pred = preds, average = 'macro')\n",
    "    return('f1_score', score_vali, True)\n",
    "\n",
    "## load data\n",
    "with open('data_w_tfidf.pkl' , 'rb') as fp :\n",
    "    Xl_train, yl_train, Xl_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named lightgbm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b00efcdb1b99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mLGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named lightgbm"
     ]
    }
   ],
   "source": [
    "#setup lightgbm\n",
    "import lightgbm as LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xl_train, Xl_vali, yl_train, yl_vali = train_test_split(Xl_train, yl_train, test_size = 0.33, random_state = 2019)\n",
    "#l_train = LGB.Dataset(data = Xl_train, label = yl_train)\n",
    "#l_vali = LGB.Dataset(data = Xl_vali, label = yl_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training data\n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'application': 'multiclassova',\n",
    "    'num_class': 19,\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'lambda_l1': 0,\n",
    "    'lambda_l2': 0.5,\n",
    "    'bagging_fraction': 1.0,\n",
    "\n",
    "}\n",
    "\n",
    "model_lgb = LGB.train(params, l_train, num_boost_round = 800, valid_sets = l_vali, feval = f1_score_vali,\n",
    "                early_stopping_rounds = None, verbose_eval=True)\n",
    "\n",
    "## save to file\n",
    "joblib.dump(model_lgb, \"./data/lgb_w_tfidf.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=4, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C = 4,dual = True)\n",
    "logreg.fit(Xl_train, yl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = logreg.predict(Xl_test)\n",
    "acc_log = round(logreg.score(Xl_vali, yl_vali) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_id = pd.read_csv('test_set.csv')[[\"id\"]].copy().as_matrix()\n",
    "submission = pd.DataFrame({\n",
    "        \"id\": test_id,\n",
    "        \"class\": Y_pred\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
